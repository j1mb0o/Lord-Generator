{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Chain Poem Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import pyphen\n",
    "import re\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So _He_ has cut his country's long ago.\n",
      "And thou--who tell'st me to rapture again.\n",
      "My boat is on the Conqueror's head!\n",
      "So _He_ has cut his country's long ago.\n",
      "I. The man who cut his throat at last!--He!\n",
      "I. The man who cut his throat at last!--He!\n",
      "Sonnet composed in the bosoms of Gath!\n",
      "So _He_ has cut his country's long ago.\n",
      "So _He_ has cut his country's long ago.\n",
      "I thought from my breast your fickle bosom please?\n"
     ]
    }
   ],
   "source": [
    "with open('byron_processed_poems.json') as f:\n",
    "    byron_poems = json.load(f)\n",
    "\n",
    "text = ' '.join([poem['lines'] for poem in byron_poems])\n",
    "text_model = markovify.Text(text, state_size=2)\n",
    "\n",
    "\n",
    "def syllable_count(sentence):\n",
    "    dic = pyphen.Pyphen(lang='en')\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    syllables = sum([len(dic.inserted(word).split('-')) for word in words])\n",
    "    return syllables\n",
    "\n",
    "def is_iambic_pentameter(sentence):\n",
    "    syllables = syllable_count(sentence)\n",
    "    return syllables == 10\n",
    "\n",
    "def generate_iambic_line():\n",
    "    while True:\n",
    "        sentence = text_model.make_sentence()\n",
    "        if sentence and is_iambic_pentameter(sentence):\n",
    "            return sentence\n",
    "\n",
    "def generate_poem(num_lines=10):\n",
    "    poem = []\n",
    "    for _ in range(num_lines):\n",
    "        line = generate_iambic_line()\n",
    "        poem.append(line)\n",
    "    return '\\n'.join(poem)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    poem = generate_poem()\n",
    "    print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Main execution block to generate and print a poem\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m     poem \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_poem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(poem)\n",
      "Cell \u001b[1;32mIn[33], line 61\u001b[0m, in \u001b[0;36mgenerate_poem\u001b[1;34m(num_lines)\u001b[0m\n\u001b[0;32m     59\u001b[0m poem \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_lines):\n\u001b[1;32m---> 61\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_iambic_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     poem\u001b[38;5;241m.\u001b[39mappend(line)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(poem)\n",
      "Cell \u001b[1;32mIn[33], line 53\u001b[0m, in \u001b[0;36mgenerate_iambic_line\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_iambic_line\u001b[39m():\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m         sentence \u001b[38;5;241m=\u001b[39m \u001b[43mtext_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sentence \u001b[38;5;129;01mand\u001b[39;00m is_iambic(sentence):\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sentence\n",
      "File \u001b[1;32mc:\\Users\\epitt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\markovify\\text.py:231\u001b[0m, in \u001b[0;36mText.make_sentence\u001b[1;34m(self, init_state, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tries):\n\u001b[1;32m--> 231\u001b[0m     words \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (max_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) \u001b[38;5;241m>\u001b[39m max_words) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    233\u001b[0m         min_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words) \u001b[38;5;241m<\u001b[39m min_words\n\u001b[0;32m    234\u001b[0m     ):\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# pragma: no cover # see coveragepy/issues/198\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\epitt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\markovify\\chain.py:142\u001b[0m, in \u001b[0;36mChain.walk\u001b[1;34m(self, init_state)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwalk\u001b[39m(\u001b[38;5;28mself\u001b[39m, init_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m    Return a list representing a single run of the Markov model, either\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    starting with a naive BEGIN state, or the provided `init_state`\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    (as a tuple).\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen(init_state))\n",
      "File \u001b[1;32mc:\\Users\\epitt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\markovify\\chain.py:130\u001b[0m, in \u001b[0;36mChain.gen\u001b[1;34m(self, init_state)\u001b[0m\n\u001b[0;32m    128\u001b[0m state \u001b[38;5;241m=\u001b[39m init_state \u001b[38;5;129;01mor\u001b[39;00m (BEGIN,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_size\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     next_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_word \u001b[38;5;241m==\u001b[39m END:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\epitt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\markovify\\chain.py:117\u001b[0m, in \u001b[0;36mChain.move\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     choices, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[state]\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m--> 117\u001b[0m     cumdist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(accumulate(weights))\n\u001b[0;32m    118\u001b[0m r \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m*\u001b[39m cumdist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    119\u001b[0m selection \u001b[38;5;241m=\u001b[39m choices[bisect\u001b[38;5;241m.\u001b[39mbisect(cumdist, r)]\n",
      "File \u001b[1;32mc:\\Users\\epitt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\markovify\\chain.py:16\u001b[0m, in \u001b[0;36maccumulate\u001b[1;34m(iterable, func)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccumulate\u001b[39m(iterable, func\u001b[38;5;241m=\u001b[39moperator\u001b[38;5;241m.\u001b[39madd):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    Cumulative calculations. (Summation, by default.)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    Via: https://docs.python.org/3/library/itertools.html#itertools.accumulate\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[0;32m     17\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(it)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m total\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import markovify\n",
    "import pronouncing\n",
    "import pyphen\n",
    "import re\n",
    "\n",
    "# Load Byron poems from JSON file\n",
    "with open('byron_processed_poems.json') as f:\n",
    "    byron_poems = json.load(f)\n",
    "\n",
    "# Prepare text for Markov model by joining all poem lines\n",
    "text = ' '.join([poem['lines'] for poem in byron_poems])\n",
    "\n",
    "# Create Markov model with state_size=2 (considers two words for each prediction)\n",
    "text_model = markovify.Text(text, state_size=2)\n",
    "\n",
    "# Function to extract stress pattern from CMU Pronouncing Dictionary\n",
    "def get_stress_pattern(word):\n",
    "    pronunciations = pronouncing.phones_for_word(word)\n",
    "    if pronunciations:\n",
    "        # Take the first pronunciation variant\n",
    "        return pronouncing.stresses(pronunciations[0])\n",
    "    return ''\n",
    "\n",
    "# Function to check if a sentence follows the unstressed-stressed iambic pattern\n",
    "def is_iambic(sentence):\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    stress_pattern = ''\n",
    "    \n",
    "    for word in words:\n",
    "        word_stress = get_stress_pattern(word.lower())\n",
    "        if word_stress:\n",
    "            stress_pattern += word_stress\n",
    "\n",
    "    # Iambic pentameter requires alternating unstressed (0) and stressed (1) pattern over 10 syllables\n",
    "    # Strip secondary stress (2) since it counts as unstressed in this context\n",
    "    stress_pattern = stress_pattern.replace('2', '0')\n",
    "    \n",
    "    # Ensure we have exactly 10 syllables\n",
    "    if len(stress_pattern) != 10:\n",
    "        return False\n",
    "\n",
    "    # Check the alternating unstressed (0) and stressed (1) pattern\n",
    "    for i in range(0, 10, 2):\n",
    "        if not (stress_pattern[i] == '0' and stress_pattern[i + 1] == '1'):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to generate a valid iambic pentameter line using the Markov model\n",
    "def generate_iambic_line():\n",
    "    while True:\n",
    "        sentence = text_model.make_sentence()\n",
    "        if sentence and is_iambic(sentence):\n",
    "            return sentence\n",
    "\n",
    "# Function to generate a full poem with a specified number of lines (default: 14 lines, sonnet form)\n",
    "def generate_poem(num_lines=14):\n",
    "    poem = []\n",
    "    for _ in range(num_lines):\n",
    "        line = generate_iambic_line()\n",
    "        poem.append(line)\n",
    "    return '\\n'.join(poem)\n",
    "\n",
    "# Main execution block to generate and print a poem\n",
    "if __name__ == \"__main__\":\n",
    "    poem = generate_poem()\n",
    "    print(poem)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
